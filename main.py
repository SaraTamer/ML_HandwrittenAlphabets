# -*- coding: utf-8 -*-
"""S1_S2_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8u72DHw6gkhyEZZJ6l6UVy0d_p_x7Ja
"""

import pandas
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, f1_score
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten

# Start with running cell of loading data if error occur start with the following cell


# Load the dataset
file_path = "A_Z Handwritten Data.csv"  # Update the file path
data = pandas.read_csv(file_path)

# Work on a random subset of 1000 rows
data = data.sample(n=5000, random_state=42)

# Identify the number of unique classes
n_classes = data.loc[:, '0'].unique().size
print("Number of unique classes:", n_classes)

# show their distribution
# Todo

X = data.drop(columns=['0'])
y = data['0']

# o Normalize each image.
# x(i) = x(i) - x(min) / x(max) - x(min)
# x(min) = 0, x(max) = 255
X = X / 255

# ● Experiments and results:
#   o Split the data into training and testing datasets
#   o First experiment (You can use scikit-learn):
#     ▪ Train 2 SVM models with linear and nonlinear kernels.
#     ▪ Test the models and provide the confusion matrix and the average f-1
#       scores for the testing dataset.

# Split the data into training and testing datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# o Reshape the flattened vectors to reconstruct and display the corresponding
# images while testing the models. [From requirement 1]
# each image is converted from [1D] 784 pixels into [2D] 28 x 28 pixels
# dataset is reshaped from 2D to 3D
X_test_reshaped = X_test.to_numpy().reshape(-1, 28, 28)

# SVM
# linear kernels

from sklearn.svm import LinearSVC
# training
linear_svm = LinearSVC(random_state=0)
linear_svm.fit(X_train, y_train)

y_pred = linear_svm.predict(X_test)

print(y_pred[2], y_test.iloc[2])

# Create image for the 2D array
plt.imshow(X_test_reshaped[2],cmap = 'gray')

# To save the trained model
# import joblib
# joblib.dump(linear_svm, 'linear_svm_model.pkl')

# Download it to your machine
# from google.colab import files
# files.download('linear_svm_model.pkl')

# SVM
# non-linear kernels

#   o Split the training dataset into training and validation datasets.
#   o Second experiment (Build from scratch):
#     ▪ Implement logistic regression for one-versus-all multi-class
#       classification.
#     ▪ Train the model and plot the error and accuracy curves for the training
#       and validation data.
#     ▪ Test the model and provide the confusion matrix and the average f-1
#       scores for the testing dataset.

# o Third experiment (You can use TensorFlow):
#   ▪ Design 2 Neural Networks (with different number of hidden layers,
#     neurons, activations, etc.)
#   ▪ Train each one of these models and plot the error and accuracy curves
#     for the training data and validation datasets.
#   ▪ Save the best model in a separated file, then reload it.
#   ▪ Test the best model and provide the confusion matrix and the average
#     f-1 scores for the testing data.
#   ▪ Test the best model with images representing the alphabetical letters
#     for the names of each member of your team.
#  o Compare the results of the models and suggest the best model.




# Simple example of a neural network structure
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),  # Hidden layer with 128 neurons
    Dense(26, activation='softmax') # Output layer (26 classes for A-Z)
])

# Preparing the model by specifying how it will learn and evaluate its performance
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


# Reshape X_train, X_test
X_train_reshaped = X_train.to_numpy().reshape(-1, 28, 28)


# Train the model
history = model.fit(X_train_reshaped, y_train, validation_split=0.2, epochs=10, batch_size=32)

# Saving the model
model.save("model.h5")


# Reload and test the best model
model = tf.keras.models.load_model("model.h5")
test_loss, test_acc = model.evaluate(X_test_reshaped, y_test, verbose=2)
print(f"Best Model Test Accuracy: {test_acc:.4f}")

